{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "718a467a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import snscrape.modules.twitter as sntwitter  # only works with python 3.11 or lower\n",
    "import pandas as pd\n",
    "import re\n",
    "import string\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import spacy\n",
    "import emoji\n",
    "from textblob import TextBlob\n",
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "from decouple import config\n",
    "import tweepy\n",
    "from datetime import datetime, timedelta, timezone\n",
    "import urllib\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "38d4e3b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Authentication successful!\n"
     ]
    }
   ],
   "source": [
    "# Load environment variables and Authenticate via tweepy\n",
    "\n",
    "BEARER_TOKEN = config(\"BEARER_TOKEN\")\n",
    "\n",
    "# Create a Tweepy Client instance for API v2\n",
    "# This is the modern and recommended way to use Tweepy\n",
    "try:\n",
    "    client = tweepy.Client(BEARER_TOKEN)\n",
    "    print(\"Authentication successful!\")\n",
    "except Exception as e:\n",
    "    print(f\"Error during authentication: {e}\")\n",
    "    # If authentication fails, we stop here.\n",
    "    # Make sure your Bearer Token is correct.\n",
    "    client = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "543e51ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully fetched 10 tweets.\n",
      "\n",
      "--- Fetched Tweets with Metadata ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "author_username",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "created_at",
         "rawType": "datetime64[ns, UTC]",
         "type": "unknown"
        },
        {
         "name": "tweet_text",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "like_count",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "216a49a5-7aea-433d-897b-5e6a91fd55df",
       "rows": [
        [
         "0",
         "LightningMike23",
         "2025-11-04 19:54:28+00:00",
         "A 10-year-old autopilot system performs nearly as well as BlueCruise. The evolution of self-driving tech is evident. #LightningMike #EV #Autopilot #BlueCruise #SelfDriving #ElectricVehicles #TechEvolution https://t.co/h4EPCVwd5S",
         "0"
        ],
        [
         "1",
         "thenewslinker",
         "2025-11-04 19:54:16+00:00",
         "Major Space Companies Launch Key Satellite Missions This November https://t.co/sfUHHw5vBh\n\nGet the latest #technology #electricvehicles #ai #robotics #cybersecurity news on NEWSLINKER!",
         "0"
        ],
        [
         "2",
         "FighterAKR",
         "2025-11-04 19:30:00+00:00",
         "Market Share of Top Electric 2-Wheeler Companies in India (FY26 YTD):-\n\n#TVSMOTOR tops India's E-2W market with 22% share. #BajajAuto (19%), #OLAELEC (17%) and #ATHERENERG (16%) closely follow. #HEROMOTOCO (10%) &amp; Others (16%) complete the picture.\n\n#ElectricVehicles #StockMarket https://t.co/w22hmKLp18",
         "0"
        ],
        [
         "3",
         "LithiumSouth",
         "2025-11-04 19:03:55+00:00",
         "CATL has started buying lithium ore from external suppliers in November due to the closure of its main Jianxiawo mine.\n\n$LIS $LISMF $OROCF $TSLA #lithium #argentina #Mining #ElectricVehicles \n\nhttps://t.co/jE8ahueahm",
         "1"
        ],
        [
         "4",
         "mindingottawa",
         "2025-11-04 19:00:29+00:00",
         "“#ElectricVehicles bring health benefits &amp; cost savings...reduce air pollution in Canadian communities &amp; reduce health care costs.”\n— Megan Nichols, AADM @environmentca \nEV Availability Standard would lower GHG emissions by 362 million tonnes over 25yrs, said Nichols. https://t.co/oJ4VZcMhaP",
         "12"
        ]
       ],
       "shape": {
        "columns": 4,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author_username</th>\n",
       "      <th>created_at</th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>like_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LightningMike23</td>\n",
       "      <td>2025-11-04 19:54:28+00:00</td>\n",
       "      <td>A 10-year-old autopilot system performs nearly...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>thenewslinker</td>\n",
       "      <td>2025-11-04 19:54:16+00:00</td>\n",
       "      <td>Major Space Companies Launch Key Satellite Mis...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>FighterAKR</td>\n",
       "      <td>2025-11-04 19:30:00+00:00</td>\n",
       "      <td>Market Share of Top Electric 2-Wheeler Compani...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LithiumSouth</td>\n",
       "      <td>2025-11-04 19:03:55+00:00</td>\n",
       "      <td>CATL has started buying lithium ore from exter...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mindingottawa</td>\n",
       "      <td>2025-11-04 19:00:29+00:00</td>\n",
       "      <td>“#ElectricVehicles bring health benefits &amp;amp;...</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   author_username                created_at  \\\n",
       "0  LightningMike23 2025-11-04 19:54:28+00:00   \n",
       "1    thenewslinker 2025-11-04 19:54:16+00:00   \n",
       "2       FighterAKR 2025-11-04 19:30:00+00:00   \n",
       "3     LithiumSouth 2025-11-04 19:03:55+00:00   \n",
       "4    mindingottawa 2025-11-04 19:00:29+00:00   \n",
       "\n",
       "                                          tweet_text  like_count  \n",
       "0  A 10-year-old autopilot system performs nearly...           0  \n",
       "1  Major Space Companies Launch Key Satellite Mis...           0  \n",
       "2  Market Share of Top Electric 2-Wheeler Compani...           0  \n",
       "3  CATL has started buying lithium ore from exter...           1  \n",
       "4  “#ElectricVehicles bring health benefits &amp;...          12  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tweet data saved to ev_tweets.csv\n"
     ]
    }
   ],
   "source": [
    "# --- SEARCHING FOR TWEETS ---\n",
    "\n",
    "if client:\n",
    "    # 1. Define search query.\n",
    "    # You can use keywords, hashtags, or more complex rules.\n",
    "    # Search for tweets about #EVs.\n",
    "    # Add '-is:retweet' to exclude retweets and get more original content.\n",
    "    # We also specify 'lang:en' to get English-language tweets.\n",
    "    query = \"#ElectricVehicles -is:retweet lang:en\"\n",
    "\n",
    "    # 2. Use the search_recent_tweets method.\n",
    "    # - The 'query' parameter is what we're searching for.\n",
    "    # - The 'max_results' parameter specifies how many tweets to return (10 to 100).\n",
    "    #   Let's fetch 10.\n",
    "    try:\n",
    "        response = client.search_recent_tweets(\n",
    "            query=query,\n",
    "            max_results=10,\n",
    "            # --- additional fields for each tweet ---\n",
    "            tweet_fields=[\n",
    "                \"created_at\",  # When the tweet was created\n",
    "                \"public_metrics\",  # Like, retweet, reply, and quote counts\n",
    "                \"author_id\",  # The ID of the user who posted\n",
    "            ],\n",
    "            # --- user information  to retrieve ---\n",
    "            expansions=[\"author_id\"],  # This tells the API to include the User object\n",
    "            user_fields=[\n",
    "                \"username\",  # The user's @handle\n",
    "                \"name\",  # The user's display name\n",
    "                \"public_metrics\",  # Follower/following counts for the user\n",
    "            ],\n",
    "        )\n",
    "\n",
    "        # 4. Process and save the enriched data\n",
    "        tweets = response.data\n",
    "        users = {user[\"id\"]: user for user in response.includes[\"users\"]} if 'users' in response.includes else {}\n",
    "\n",
    "        if tweets:\n",
    "            print(f\"Successfully fetched {len(tweets)} tweets.\")\n",
    "            \n",
    "            # Create a list to hold our structured data\n",
    "            tweet_data = []\n",
    "            for tweet in tweets:\n",
    "                author = users.get(tweet.author_id)\n",
    "                if author:\n",
    "                    tweet_data.append({\n",
    "                        'author_name': author.name,\n",
    "                        'author_username': author.username,\n",
    "                        'author_followers': author.public_metrics.get('followers_count', 0),\n",
    "                        'created_at': tweet.created_at,\n",
    "                        'tweet_text': tweet.text,\n",
    "                        'like_count': tweet.public_metrics.get('like_count', 0),\n",
    "                        'retweet_count': tweet.public_metrics.get('retweet_count', 0),\n",
    "                        'reply_count': tweet.public_metrics.get('reply_count', 0)\n",
    "                    })\n",
    "\n",
    "            # 5. Convert the list of dictionaries into a pandas DataFrame\n",
    "            df = pd.DataFrame(tweet_data)\n",
    "            \n",
    "            print(\"\\n--- Fetched Tweets with Metadata ---\")\n",
    "            # Display a few key columns of the DataFrame\n",
    "            display(df[['author_username', 'created_at', 'tweet_text', 'like_count']].head())\n",
    "\n",
    "            # 6. Save the dataset to a CSV file\n",
    "            df.to_csv('ev_tweets.csv', index=False)\n",
    "            print(\"\\nTweet data saved to ev_tweets.csv\")\n",
    "\n",
    "        else:\n",
    "            print(\"No tweets found for your query. Try a different keyword or hashtag.\")\n",
    "\n",
    "    except tweepy.errors.TweepyException as e:\n",
    "        # Handles API-specific errors, like the 429 Too Many Requests\n",
    "        print(f\"A Tweepy error occurred: {e}\")\n",
    "    except ConnectionError as e:\n",
    "        # Specifically catches network-related errors like the one you saw\n",
    "        print(f\"A network connection error occurred: {e}\")\n",
    "        print(\n",
    "            \"This is often temporary. Please check your internet connection and try again in a few moments.\"\n",
    "        )\n",
    "    except Exception as e:\n",
    "        # Catches any other unexpected errors\n",
    "        print(f\"An unexpected error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6d55b8d",
   "metadata": {},
   "source": [
    "## 2. Data Cleaning and Preparation\n",
    "\n",
    "Clean and prepare the tweet text data for sentiment analysis.\n",
    "The steps include:\n",
    "\n",
    "1. Removing URLs, mentions, hashtags (or removing the ‘#’ but keeping the word), emojis and special characters\n",
    "2. Converting text to lowercase\n",
    "3. Tokenizing the text\n",
    "4. Removing stop-words\n",
    "5. Lemmatizing the tokens\n",
    "6. Rebuilding the cleaned text field\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8ec3f9ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/3n61n33r/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/3n61n33r/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/3n61n33r/nltk_data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     /Users/3n61n33r/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('punkt_tab')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "bc78b02c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Successfully loaded ev_tweets.csv ---\n",
      "Original number of tweets: 10\n",
      "Number of tweets after removing duplicates: 10\n",
      "\n",
      "--- Data After Full Cleaning and Processing ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_0f4bd_row0_col0, #T_0f4bd_row0_col1, #T_0f4bd_row1_col0, #T_0f4bd_row1_col1, #T_0f4bd_row2_col0, #T_0f4bd_row2_col1, #T_0f4bd_row3_col0, #T_0f4bd_row3_col1, #T_0f4bd_row4_col0, #T_0f4bd_row4_col1 {\n",
       "  text-align: left;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_0f4bd\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_0f4bd_level0_col0\" class=\"col_heading level0 col0\" >tweet_text</th>\n",
       "      <th id=\"T_0f4bd_level0_col1\" class=\"col_heading level0 col1\" >cleaned_tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_0f4bd_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_0f4bd_row0_col0\" class=\"data row0 col0\" >A 10-year-old autopilot system performs nearly as well as BlueCruise. The evolution of self-driving tech is evident. #LightningMike #EV #Autopilot #BlueCruise #SelfDriving #ElectricVehicles #TechEvolution https://t.co/h4EPCVwd5S</td>\n",
       "      <td id=\"T_0f4bd_row0_col1\" class=\"data row0 col1\" >yearold autopilot system performs nearly well bluecruise evolution selfdriving tech evident lightningmike autopilot bluecruise selfdriving electricvehicles techevolution</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_0f4bd_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_0f4bd_row1_col0\" class=\"data row1 col0\" >Major Space Companies Launch Key Satellite Missions This November https://t.co/sfUHHw5vBh\n",
       "\n",
       "Get the latest #technology #electricvehicles #ai #robotics #cybersecurity news on NEWSLINKER!</td>\n",
       "      <td id=\"T_0f4bd_row1_col1\" class=\"data row1 col1\" >major space company launch key satellite mission november get latest technology electricvehicles robotics cybersecurity news newslinker</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_0f4bd_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_0f4bd_row2_col0\" class=\"data row2 col0\" >Market Share of Top Electric 2-Wheeler Companies in India (FY26 YTD):-\n",
       "\n",
       "#TVSMOTOR tops India's E-2W market with 22% share. #BajajAuto (19%), #OLAELEC (17%) and #ATHERENERG (16%) closely follow. #HEROMOTOCO (10%) &amp; Others (16%) complete the picture.\n",
       "\n",
       "#ElectricVehicles #StockMarket https://t.co/w22hmKLp18</td>\n",
       "      <td id=\"T_0f4bd_row2_col1\" class=\"data row2 col1\" >market share top electric wheeler company india ytd tvsmotor top india market share bajajauto olaelec atherenerg closely follow heromotoco others complete picture electricvehicles stockmarket</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_0f4bd_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_0f4bd_row3_col0\" class=\"data row3 col0\" >CATL has started buying lithium ore from external suppliers in November due to the closure of its main Jianxiawo mine.\n",
       "\n",
       "$LIS $LISMF $OROCF $TSLA #lithium #argentina #Mining #ElectricVehicles \n",
       "\n",
       "https://t.co/jE8ahueahm</td>\n",
       "      <td id=\"T_0f4bd_row3_col1\" class=\"data row3 col1\" >catl started buying lithium ore external supplier november due closure main jianxiawo mine li lismf orocf tsla lithium argentina mining electricvehicles</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_0f4bd_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_0f4bd_row4_col0\" class=\"data row4 col0\" >“#ElectricVehicles bring health benefits &amp; cost savings...reduce air pollution in Canadian communities &amp; reduce health care costs.”\n",
       "— Megan Nichols, AADM @environmentca \n",
       "EV Availability Standard would lower GHG emissions by 362 million tonnes over 25yrs, said Nichols. https://t.co/oJ4VZcMhaP</td>\n",
       "      <td id=\"T_0f4bd_row4_col1\" class=\"data row4 col1\" >electricvehicles bring health benefit cost savingsreduce air pollution canadian community reduce health care cost megan nichols aadm availability standard would lower ghg emission million tonne yr said nichols</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x11c8df3d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import html\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "# Load the enriched data from the CSV file.\n",
    "try:\n",
    "    df = pd.read_csv('ev_tweets.csv')\n",
    "    print(\"--- Successfully loaded ev_tweets.csv ---\")\n",
    "    print(f\"Original number of tweets: {len(df)}\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: {df} not found.\")\n",
    "    df = None\n",
    "\n",
    "if df is not None:\n",
    "    # emove duplicate tweets based on the 'tweet_text' column.\n",
    "    df.drop_duplicates(subset='tweet_text', inplace=True)\n",
    "    print(f\"Number of tweets after removing duplicates: {len(df)}\")\n",
    "\n",
    "    # 3. Initialize the lemmatizer and stop-words list.\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "\n",
    "    # Define the comprehensive cleaning function.\n",
    "    def clean_and_process_tweet(text):\n",
    "        # Step A: Basic Cleaning (URLs, mentions, special characters)\n",
    "        text = html.unescape(text)  # Handle HTML entities like &amp;\n",
    "        text = re.sub(r'http\\S+|www\\S+', '', text, flags=re.MULTILINE ) # Remove URLs\n",
    "        text = re.sub(r'\\@\\w+|\\#','', text) # Remove mentions and hashtags\n",
    "        text = re.sub(r'[^A-Za-z\\s]+', '', text) # Remove special characters and numbers\n",
    "        text = text.lower() # Convert to lowercase\n",
    "\n",
    "        # Step B: Tokenization\n",
    "        tokens = word_tokenize(text)\n",
    "\n",
    "        # Step C: Stop-word removal and Lemmatization\n",
    "        cleaned_tokens = []\n",
    "        for word in tokens:\n",
    "            if word not in stop_words and len(word) > 2: # Filter out stop-words and short words\n",
    "                cleaned_tokens.append(lemmatizer.lemmatize(word))\n",
    "\n",
    "        # Join the tokens back into a single string\n",
    "        return \" \".join(cleaned_tokens)\n",
    "\n",
    "    # Apply the function to create the 'cleaned_tweet' column.\n",
    "    df['cleaned_tweet'] = df['tweet_text'].apply(clean_and_process_tweet)\n",
    "\n",
    "    # 6. Display the results for verification.\n",
    "    print(\"\\n--- Data After Full Cleaning and Processing ---\")\n",
    "    # Using .style.set_properties to wrap text for better readability\n",
    "    display(df[['tweet_text', 'cleaned_tweet']].head().style.set_properties(**{'text-align': 'left', 'white-space': 'pre-wrap'}))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e58609d4",
   "metadata": {},
   "source": [
    "The raw text data collected from X (formerly Twitter) is unstructured and contains a significant amount of \"noise\" that can interfere with accurate analysis. To prepare the data for Natural Language Processing (NLP), a comprehensive cleaning and preprocessing pipeline was applied to the tweet_text column.\n",
    "The following key steps were performed:\n",
    "\n",
    "1. Load and Deduplicate Data: The dataset was first loaded from the ev_tweets_with_metadata.csv file. Any duplicate tweets were removed to ensure that the analysis is not biased by repeated content.\n",
    "2. HTML Decoding: Text often contains HTML character codes (e.g., &amp; for &). These were decoded back into standard characters to ensure proper readability and processing.\n",
    "3. Removal of Noise Elements:\n",
    "    URLs: All hyperlinks (e.g., https://t.co/... ) were removed as they do not contribute to the semantic meaning of the tweet.\n",
    "    User Mentions and Hashtags: Mentions (@username) and the hash symbol (#) from hashtags were removed to isolate the keywords themselves.\n",
    "    Special Characters and Numbers: All non-alphabetic characters, including punctuation, emojis, and numbers, were stripped from the text to focus solely on the words.\n",
    "4. Text Normalization:\n",
    "    Lowercasing: The entire text was converted to lowercase. This ensures that words like \"EV\", \"Ev\", and \"ev\" are treated as the same token, preventing dilution of word frequency counts.\n",
    "5. Tokenization: Each cleaned tweet was broken down into a list of individual words or \"tokens\". This is a foundational step for any word-level analysis.\n",
    "6. Stop-Word Removal: Common English words that provide little semantic value (e.g., \"the\", \"a\", \"in\", \"is\") are known as stop-words. These were filtered out from the list of tokens to help focus the analysis on the most meaningful words.\n",
    "7. Lemmatization: The final step was to reduce words to their base or dictionary form (their \"lemma\"). For example, \"driving,\" \"drives,\" and \"drove\" were all converted to \"drive.\" This standardizes words and is crucial for accurately identifying the core topics and themes within the text.\n",
    "\n",
    "The final processed text was stored in a new column named cleaned_tweet.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa003e1a",
   "metadata": {},
   "source": [
    "## 3. Sentiment Analysis\n",
    "\n",
    "In this section, we will analyze the sentiment of our cleaned tweets using three different approaches:\n",
    "\n",
    "1. **TextBlob** – simple polarity-based sentiment scoring\n",
    "\n",
    "\n",
    "- Polarity Score: TextBlob is applied to each string in the cleaned_tweet column to calculate a sentiment polarity score, which ranges from -1.0 (most negative) to +1.0 (most positive).\n",
    "- Sentiment Classification: A function is defined to classify each tweet based on its polarity score:\n",
    "        Positive: Polarity > 0.1\n",
    "        Negative: Polarity < -0.1\n",
    "        Neutral: Polarity between -0.1 and 0.1\n",
    "  A threshold of 0.1 is used instead of 0 to avoid classifying tweets with very weak sentiment as Positive or Negative).\n",
    "- Aggregation: The sentiment classification for each tweet is stored in a new sentiment column. Finally, the overall distribution of sentiments across the entire dataset is calculated and displayed.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "557cc161",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Tweets with Classified Sentiment ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "cleaned_tweet",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "sentiment",
         "rawType": "object",
         "type": "string"
        }
       ],
       "ref": "907603f6-0e93-4b16-888b-a1a8aeaa3da7",
       "rows": [
        [
         "0",
         "yearold autopilot system performs nearly well bluecruise evolution selfdriving tech evident lightningmike autopilot bluecruise selfdriving electricvehicles techevolution",
         "Positive"
        ],
        [
         "1",
         "major space company launch key satellite mission november get latest technology electricvehicles robotics cybersecurity news newslinker",
         "Positive"
        ],
        [
         "2",
         "market share top electric wheeler company india ytd tvsmotor top india market share bajajauto olaelec atherenerg closely follow heromotoco others complete picture electricvehicles stockmarket",
         "Positive"
        ],
        [
         "3",
         "catl started buying lithium ore external supplier november due closure main jianxiawo mine li lismf orocf tsla lithium argentina mining electricvehicles",
         "Neutral"
        ],
        [
         "4",
         "electricvehicles bring health benefit cost savingsreduce air pollution canadian community reduce health care cost megan nichols aadm availability standard would lower ghg emission million tonne yr said nichols",
         "Neutral"
        ]
       ],
       "shape": {
        "columns": 2,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cleaned_tweet</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>yearold autopilot system performs nearly well ...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>major space company launch key satellite missi...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>market share top electric wheeler company indi...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>catl started buying lithium ore external suppl...</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>electricvehicles bring health benefit cost sav...</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       cleaned_tweet sentiment\n",
       "0  yearold autopilot system performs nearly well ...  Positive\n",
       "1  major space company launch key satellite missi...  Positive\n",
       "2  market share top electric wheeler company indi...  Positive\n",
       "3  catl started buying lithium ore external suppl...   Neutral\n",
       "4  electricvehicles bring health benefit cost sav...   Neutral"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Overall Sentiment Distribution ---\n",
      "sentiment\n",
      "Positive    60.0\n",
      "Neutral     40.0\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from textblob import TextBlob\n",
    "\n",
    "\n",
    "# Define the function to get sentiment polarity and classify it.\n",
    "def get_sentiment(text):\n",
    "    \"\"\"\n",
    "    Analyzes the text and returns a sentiment category:\n",
    "    'Positive', 'Negative', or 'Neutral'.\n",
    "    \"\"\"\n",
    "    analysis = TextBlob(text)\n",
    "    # Classify based on polarity\n",
    "    if analysis.sentiment.polarity > 0.1:\n",
    "        return 'Positive'\n",
    "    elif analysis.sentiment.polarity < -0.1:\n",
    "        return 'Negative'\n",
    "    else:\n",
    "        return 'Neutral'\n",
    "\n",
    "# 2. Apply the function to the 'cleaned_tweet' column to create a new 'sentiment' column.\n",
    "# We run this on the cleaned text for a more accurate analysis.\n",
    "df['sentiment'] = df['cleaned_tweet'].apply(get_sentiment)\n",
    "\n",
    "# 3. Display the tweets along with their calculated sentiment.\n",
    "print(\"--- Tweets with Classified Sentiment ---\")\n",
    "display(df[['cleaned_tweet', 'sentiment']].head())\n",
    "\n",
    "# 4. Calculate and display the overall sentiment distribution.\n",
    "print(\"\\n--- Overall Sentiment Distribution ---\")\n",
    "sentiment_distribution = df['sentiment'].value_counts(normalize=True) * 100\n",
    "print(sentiment_distribution)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f07469af",
   "metadata": {},
   "source": [
    "### Visualizing sentiment distribution\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45ba8c18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sentiment distribution\n",
    "sns.set(style=\"whitegrid\")\n",
    "plt.figure(figsize=(7, 5))\n",
    "sns.countplot(x=\"sentiment\", data=df, order=[\"Positive\", \"Neutral\", \"Negative\"])\n",
    "plt.title(\"Sentiment Distribution (TextBlob)\")\n",
    "plt.xlabel(\"Sentiment\")\n",
    "plt.ylabel(\"Number of Tweets\")\n",
    "plt.show()\n",
    "\n",
    "# Average polarity\n",
    "avg_sentiment = df[\"polarity\"].mean()\n",
    "print(f\"Average Sentiment Polarity: {avg_sentiment:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01bd2143",
   "metadata": {},
   "source": [
    "#### Using VADER (Better for social media text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb5bf418",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faabeab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "\n",
    "# Apply VADER to each tweet\n",
    "df[\"vader_scores\"] = df[\"cleaned_joined\"].apply(\n",
    "    lambda x: analyzer.polarity_scores(str(x))[\"compound\"]\n",
    ")\n",
    "\n",
    "# Convert to categorical sentiment\n",
    "df[\"vader_sentiment\"] = df[\"vader_scores\"].apply(\n",
    "    lambda s: \"Positive\" if s > 0.05 else (\"Negative\" if s < -0.05 else \"Neutral\")\n",
    ")\n",
    "\n",
    "# Visualization\n",
    "plt.figure(figsize=(7, 5))\n",
    "sns.countplot(\n",
    "    x=\"vader_sentiment\",\n",
    "    data=df,\n",
    "    order=[\"Positive\", \"Neutral\", \"Negative\"],\n",
    "    palette=\"pastel\",\n",
    ")\n",
    "plt.title(\"Sentiment Distribution (VADER)\")\n",
    "plt.xlabel(\"Sentiment\")\n",
    "plt.ylabel(\"Number of Tweets\")\n",
    "plt.show()\n",
    "\n",
    "# Average sentiment score\n",
    "avg_vader = df[\"vader_scores\"].mean()\n",
    "print(f\"Average VADER Sentiment Score: {avg_vader:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "117b1914",
   "metadata": {},
   "source": [
    "### Interpretation of Results\n",
    "\n",
    "From the TextBlob and VADER analyses, we can observe that:\n",
    "\n",
    "- The majority of tweets around **#ElectricVehicles** are positive, showing enthusiasm about EV technology and sustainability.\n",
    "- Neutral tweets mostly share factual updates (e.g., government policy or product announcements).\n",
    "- Negative tweets often discuss high costs, range anxiety, or charging challenges.\n",
    "\n",
    "The VADER model produced slightly more neutral classifications compared to TextBlob, which tends to exaggerate positive sentiment. The optional Transformer model provides more context-aware scoring and aligns more closely with nuanced opinions.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa9c0999",
   "metadata": {},
   "source": [
    "## 4. Word Cloud Visualization\n",
    "\n",
    "To complement the sentiment analysis, we will visualize the most frequent words used in the tweets through a **word cloud**.  \n",
    "A word cloud shows words sized proportionally to their frequency — larger words appear more often in the dataset.\n",
    "\n",
    "This helps identify common themes or discussion points around our topic (**#ElectricVehicles**).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3b2e6ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud, STOPWORDS\n",
    "\n",
    "# Combine all cleaned text\n",
    "text_all = \" \".join(df[\"cleaned_joined\"].astype(str))\n",
    "\n",
    "# Add default and custom stopwords to filter out uninformative words\n",
    "stopwords = set(STOPWORDS)\n",
    "custom_stopwords = {\"https\", \"co\", \"rt\", \"amp\"}  # common Twitter noise\n",
    "stopwords.update(custom_stopwords)\n",
    "\n",
    "# Generate the word cloud\n",
    "wordcloud = WordCloud(\n",
    "    width=1000,\n",
    "    height=600,\n",
    "    background_color=\"white\",\n",
    "    stopwords=stopwords,\n",
    "    collocations=False,\n",
    "    max_words=150,\n",
    ").generate(text_all)\n",
    "\n",
    "# Display it\n",
    "plt.figure(figsize=(12, 7))\n",
    "plt.imshow(wordcloud, interpolation=\"bilinear\")\n",
    "plt.axis(\"off\")\n",
    "plt.title(\"Most Frequent Words in #ElectricVehicles Tweets\", fontsize=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9309fd7",
   "metadata": {},
   "source": [
    "### Interpretation of Themes\n",
    "\n",
    "- Words such as **“tesla”, “battery”, “charging”, “price”, “sustainability”** may appear most frequently, reflecting public focus on technology, cost, and environmental impact.\n",
    "- If policy-related terms appear (e.g., “subsidy”, “government”, “incentive”), they indicate discussion around regulation and infrastructure.\n",
    "- The presence of **positive** words (e.g., “love”, “future”, “innovation”) or **negative** ones (e.g., “expensive”, “problem”, “delay”) complements the sentiment analysis findings.\n",
    "\n",
    "### Summary of Step 4\n",
    "\n",
    "The word cloud provides a quick visual summary of the conversation landscape and helps identify keywords driving positive or negative sentiment.  \n",
    "Together with Step 3’s sentiment plots, it gives a comprehensive overview of public mood toward **#ElectricVehicles**.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Applications-of-AI-ItjPKJgw",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
